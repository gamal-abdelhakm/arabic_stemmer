{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أشباه\n",
      "إعراب\n",
      "جليل\n",
      "تحرير\n",
      "تفرد\n",
      "تقويم\n",
      "تهاب\n",
      "جمالي\n",
      "حبش\n",
      "صوص\n",
      "سمسر\n",
      "ولوج\n",
      "عراف\n",
      "فرقد\n",
      "لسوف\n",
      "مركز\n",
      "منهج\n",
      "ثماتي\n",
      "نمطي\n",
      "إلمام\n",
      "مخرج\n",
      "مدني\n",
      "مذكرة\n",
      "مرسوم\n",
      "مساحيق\n",
      "مسال\n",
      "مصمم\n",
      "عاصر\n",
      "مقرر\n",
      "مكيف\n",
      "ملاك\n",
      "ملتح\n",
      "نحنى\n",
      "نائي\n",
      "نبذة\n",
      "نسيج\n",
      "نظامي\n",
      "نعناع\n",
      "هزلي\n",
      "واهي\n",
      "حشية\n",
      "وعيد\n",
      "هودي\n",
      "وناني\n",
      "يفور\n",
      "يكود\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_diacritics(word):\n",
    "    return re.sub('[\\u064b-\\u0652]', '', word)\n",
    "\n",
    "def remove_prefix(word, prefixes):\n",
    "    for prefix in prefixes:\n",
    "        if word.startswith(prefix):\n",
    "            return word[len(prefix):]\n",
    "    return word\n",
    "\n",
    "def remove_suffix(word, suffixes):\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "def pattern_encoder(word):\n",
    "    mapping = {'ا': '1', 'و': '2', 'ي': '3', 'م': '4','ة': '5','ت':'6'}\n",
    "    encoded_word = ''.join(mapping.get(letter, '0') for letter in word)\n",
    "    if not encoded_word.startswith('4'):\n",
    "        encoded_word = encoded_word.replace('4', '0', 1)\n",
    "    return encoded_word\n",
    "\n",
    "def match_pattern(word, patterns):\n",
    "  for pattern in patterns:\n",
    "    found = True\n",
    "    if len(pattern) == len(word):\n",
    "      #print(pattern, word)\n",
    "      for letter in range(len(word)):\n",
    "      \n",
    "            if pattern[letter] != '0' and pattern[letter] != word[letter]:\n",
    "                  #print(pattern[letter], word[letter])\n",
    "                  found = False\n",
    "                  break\n",
    "\n",
    "    elif len(pattern) != len(word):\n",
    "              found = False\n",
    "    if found == True:\n",
    "              return True\n",
    "  return False\n",
    "\n",
    "\n",
    "\n",
    "def stem(word):\n",
    "    prefixes = ['ال', 'و', 'ب', 'ف', 'ل', 'ك', 'ي', 'س', 'ت', 'ن', 'أ', 'م', 'إ', 'ع', 'ح', 'ر', 'ز', 'ص', 'غ', 'ض', 'ذ', 'ش', 'ظ', 'ث', 'خ', 'ج']\n",
    "    suffixes = ['ا','ات','ان','انا','اني','ي','ة','ت','تا','تان','تما','تن','ته','تها','تهم','تهما','تهن','تي','تين','ك','كم','كما','م','ما','ون','ن','نا','ني','ه','ها','هم','هما','هن','وا','ونا','وني','يا','يت','يتان','ين','ينا','يني']\n",
    "    patterns = ['تفعيل','فعال','فاعل', 'فعيل', 'مفعول', 'مفعل', 'مفعيل', 'مفعلة', 'مفاعيل', 'مفاعلة','أفعال','فعالي']\n",
    "\n",
    "    encoded_patterns = []\n",
    "    for pattern in patterns:\n",
    "        encoded_patterns.append(pattern_encoder(pattern))\n",
    "\n",
    "    word = remove_diacritics(word)\n",
    "    #if pattern_encoder(word) in encoded_patterns:\n",
    "    if match_pattern(pattern_encoder(word), encoded_patterns):\n",
    "            return word\n",
    "    \n",
    "    temp = ''\n",
    "    while len(word) > 4 and temp != word:\n",
    "        temp = word\n",
    "\n",
    "        word = remove_suffix(word, suffixes) \n",
    "        #if pattern_encoder(word) in encoded_patterns:\n",
    "        if match_pattern(pattern_encoder(word), encoded_patterns):\n",
    "            return word\n",
    "        #print('suf ',word)\n",
    "        \n",
    "        word = temp\n",
    "        word = remove_prefix(word, prefixes)\n",
    "        #if pattern_encoder(word) in encoded_patterns:\n",
    "        if match_pattern(pattern_encoder(word), encoded_patterns):\n",
    "            return word \n",
    "        #print('pre ',word)\n",
    "\n",
    "        word = remove_suffix(word, suffixes) \n",
    "        #if pattern_encoder(word) in encoded_patterns:\n",
    "        if match_pattern(pattern_encoder(word), encoded_patterns):\n",
    "            return word\n",
    "        #print('suf ',word)\n",
    "        \n",
    "    \n",
    "    return word\n",
    "\n",
    "words = ['المقاولين','المصدرين','المجالات','الرؤوس','المتناقض','المدرسون','التعاونيات','الاستقلالية','أفتكاتبانني','المركزية','تعليمات','مشاريع','احترافية','أفتضاربانني']\n",
    "words = ['أشباه', 'إعراب', 'إجليلي', 'التحرير', 'التفرد', 'التقويم', 'التهاب', 'الجماليات', 'الحبشة', 'الخصوصية', 'السمسرة', 'السوسيولوجية', 'العرافة', 'الفرقداني', 'الفيلسوفي', 'المركزية', 'المنهجية', 'الميثماتيكية', 'النمطية', 'إلمام', 'مخرج', 'مدني', 'مذكرة', 'مرسوم', 'مساحيق', 'مسالك', 'مصمم', 'معاصر', 'مقررات', 'مكيف', 'ملاك', 'ملتحي', 'منحنى', 'نائية', 'نبذة', 'نسيجي', 'نظامية', 'نعناعي', 'هزلي', 'واهية', 'وحشية', 'وعيد', 'يهودية', 'يونانية', 'يونيفورم', 'يونيكود']\n",
    "for word in words:\n",
    "    print(stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MG_Stemmer:\n",
    "    def __init__(self):\n",
    "        self.prefixes = ['ال', 'و', 'ب', 'ف', 'ل', 'ك', 'ي', 'س', 'ت', 'ن', 'أ', 'م', 'إ', 'ع', 'ح', 'ر', 'ز', 'ص', 'غ', 'ض', 'ذ', 'ش', 'ظ', 'ث', 'خ', 'ج']\n",
    "        self.suffixes = ['ا','ات','ان','انا','اني','ي','ة','ت','تا','تان','تما','تن','ته','تها','تهم','تهما','تهن','تي','تين','ك','كم','كما','م','ما','ون','ن','نا','ني','ه','ها','هم','هما','هن','وا','ونا','وني','يا','يت','يتان','ين','ينا','يني']\n",
    "        self.patterns = ['تفعيل','فعال','فاعل', 'فعيل', 'مفعول', 'مفعل', 'مفعيل', 'مفعلة', 'مفاعيل', 'مفاعلة','أفعال','فعالي']\n",
    "        self.mapping = {'ا': '1', 'و': '2', 'ي': '3', 'م': '4','ة': '5','ت':'6'}\n",
    "        self.encoded_patterns = [self.pattern_encoder(pattern) for pattern in self.patterns]\n",
    "\n",
    "    def remove_diacritics(self, word):\n",
    "        return re.sub('[\\u064b-\\u0652]', '', word)\n",
    "\n",
    "    def remove_prefix(self, word, prefixes):\n",
    "        for prefix in prefixes:\n",
    "            if word.startswith(prefix):\n",
    "                return word[len(prefix):]\n",
    "        return word\n",
    "\n",
    "    def remove_suffix(self, word, suffixes):\n",
    "        for suffix in suffixes:\n",
    "            if word.endswith(suffix):\n",
    "                return word[:-len(suffix)]\n",
    "        return word\n",
    "\n",
    "    def pattern_encoder(self, word):\n",
    "        encoded_word = ''.join(self.mapping.get(letter, '0') for letter in word)\n",
    "        if not encoded_word.startswith('4'):\n",
    "            encoded_word = encoded_word.replace('4', '0', 1)\n",
    "        return encoded_word\n",
    "\n",
    "    def match_pattern(self, word, patterns):\n",
    "        for pattern in patterns:\n",
    "            found = True\n",
    "            if len(pattern) == len(word):\n",
    "                for letter in range(len(word)):\n",
    "                    if pattern[letter] != '0' and pattern[letter] != word[letter]:\n",
    "                        found = False\n",
    "                        break\n",
    "            elif len(pattern) != len(word):\n",
    "                found = False\n",
    "            if found == True:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def stem(self, word):\n",
    "        word = self.remove_diacritics(word)\n",
    "        if self.match_pattern(self.pattern_encoder(word), self.encoded_patterns):\n",
    "            return word\n",
    "        temp = ''\n",
    "        while len(word) > 4 and temp != word:\n",
    "            temp = word\n",
    "            word = self.remove_suffix(word, self.suffixes) \n",
    "            if self.match_pattern(self.pattern_encoder(word), self.encoded_patterns):\n",
    "                return word\n",
    "            word = temp\n",
    "            word = self.remove_prefix(word, self.prefixes)\n",
    "            if self.match_pattern(self.pattern_encoder(word), self.encoded_patterns):\n",
    "                return word \n",
    "            word = self.remove_suffix(word, self.suffixes) \n",
    "            if self.match_pattern(self.pattern_encoder(word), self.encoded_patterns):\n",
    "                return word\n",
    "        return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مقاول\n",
      "مصدر\n",
      "مجال\n",
      "رؤوس\n",
      "ناقض\n",
      "مدرس\n",
      "عاون\n",
      "استقلال\n",
      "كاتب\n",
      "مركز\n",
      "تعليم\n",
      "مشاريع\n",
      "احتراف\n",
      "ضارب\n"
     ]
    }
   ],
   "source": [
    "mg = MG_Stemmer()\n",
    "words = ['المقاولين','المصدرين','المجالات','الرؤوس','المتناقض','المدرسون','التعاونيات','الاستقلالية','أفتكاتبانني','المركزية','تعليمات','مشاريع','احترافية','أفتضاربانني']\n",
    "#words = ['أشباه', 'إعراب', 'إجليلي', 'التحرير', 'التفرد', 'التقويم', 'التهاب', 'الجماليات', 'الحبشة', 'الخصوصية', 'السمسرة', 'السوسيولوجية', 'العرافة', 'الفرقداني', 'الفيلسوفي', 'المركزية', 'المنهجية', 'الميثماتيكية', 'النمطية', 'إلمام', 'مخرج', 'مدني', 'مذكرة', 'مرسوم', 'مساحيق', 'مسالك', 'مصمم', 'معاصر', 'مقررات', 'مكيف', 'ملاك', 'ملتحي', 'منحنى', 'نائية', 'نبذة', 'نسيجي', 'نظامية', 'نعناعي', 'هزلي', 'واهية', 'وحشية', 'وعيد', 'يهودية', 'يونانية', 'يونيفورم', 'يونيكود']\n",
    "for word in words:\n",
    "    print(mg.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مقاول\n",
      "مصدر\n",
      "مجال\n",
      "رؤوس\n",
      "ناقض\n",
      "مدرس\n",
      "عاون\n",
      "استقلال\n",
      "كاتب\n",
      "مركز\n",
      "تعليم\n",
      "مشاريع\n",
      "احتراف\n",
      "ضارب\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شبا\n",
      "إعراب\n",
      "إجليل\n",
      "تحرير\n",
      "تفرد\n",
      "تقويم\n",
      "تهاب\n",
      "جمال\n",
      "حبش\n",
      "خصوص\n",
      "سمسر\n",
      "السوسيولوجية\n",
      "عراف\n",
      "فرقدان\n",
      "فيلسوف\n",
      "مركز\n",
      "منهج\n",
      "الميثماتيكية\n",
      "نمط\n",
      "إلمام\n",
      "مخرج\n",
      "مد\n",
      "مذكر\n",
      "مرسوم\n",
      "مساحيق\n",
      "مسال\n",
      "مصمم\n",
      "معاصر\n",
      "مقرر\n",
      "مكيف\n",
      "مل\n",
      "ملتح\n",
      "منحنى\n",
      "نائ\n",
      "نبذ\n",
      "سيجي\n",
      "نظام\n",
      "نعناع\n",
      "هزل\n",
      "اه\n",
      "حش\n",
      "عيد\n",
      "يهود\n",
      "يونان\n",
      "يونيفورم\n",
      "يونيكود\n"
     ]
    }
   ],
   "source": [
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "ArListem = ArabicLightStemmer()\n",
    "for word in words:\n",
    "    stem = ArListem.light_stem(word)\n",
    "    print (ArListem.get_stem())\n",
    "    #print (ArListem.get_root())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
